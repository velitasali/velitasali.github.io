---
layout: post
title:  "Understanding Artificial Intelligence"
date:   2019-02-03 18:00 +0300
categories: opinion
published: true
---
*This was a paper for one of the classes I participated. The class was nowhere near computer engineering. Please treat it accordingly. You can sent your thoughts to my e-mail address.*

When it is considered, most of us creates solvable problems to assert a meaning to life. I am not talking about deeply religious people. I am talking of those who take a large portion of the human society and those are the ones that define the rules of what we live in. Whether it is impossible to apply it to all, we are in need of the knowledge that could help us understand what is going on in our universe and existence. AI holds a new way of understanding in this and, yet people also have many different approaches to the topic. Some believes it should never come to life at all, because it is dangerous and some believes it will cause human to lose their purpose of life. There are also those like me who believe it offers endless opportunities that we can get the benefit of.
It is a bit disturbing to see how we are directly addressing AI as evil. But to my understanding when we eliminate the fact that human errs and human does evil, it appears that AI is the most beneficial technology that could have ever occurred in the human history. Without having the replacement of the humans, an AI can help us develop better machines to accompany us or they can improve the quality of our lives, so that we can finally focus more on it in some respects. Diseases and other unexpected failures could still occur, but we still would be able to see a better treatment while curing or fixing them.
It is not a must to put AI in the center of everything and that would be dangerous. Because when we do so, it would be hard to know when its hacked and to be honest, we humans can also be hacked. So my offering is that they should never in control or given power at any time. However, I believe that sending them to long missions to collect data would be the most useful of them like, for example, into a black hole in the space.
Another question that arises whether AI with a true consciousness supported by chemical reactions to enable it to reflect human feelings would suffer from pain as we do. The development of AI have not taken the shape which we can name as ideal (as it is not successful). So the randomness of living objects which is triggered by chemical reactions could help us develop an AI with feelings. However, if it is the case that this is to involve in the development, then it might force us to question whether the morals of this development should be revised before sending them to deadly missions.
AI does make sense as does the topics it involves in. Our lives are meaningless and that is why we write romantic books or science-fiction or that is the reason we speak different languages. To assert a meaning to live we chose to be not understood. All the songs, movies, drama plays, games (counting video games in) point out one thing and that is we create problems to have a more meaningful lives. We define what is good and what is beautiful and nice so that human imperfections could be forgotten for a moment. We do the evil because we are bored and we do the good because it certifies that there is evil and these are meaningful and at the same time non-sense.

**What is & What is not?**

Artificial Intelligence has different definitions and understanding among by whom they are defined. Its definitions are simply endless and has no one specific understanding as the current usage of the term suggests. So it is better not to define but to explain what it actually is.
The Artificial Intelligence with its most known definition is a part of machine that can use its provided hardware in a certain way that it can learn in some aspects and then can judge its environment by using what it has gathered. It is not simply a computer program because it can be dependent on without really interfering the way it works while working. That is why we are seeing “AI-powered” statement on some devices, donating that it can handle some tasks without really expecting an user-input.
There is another definition of it which we know and come across the most and it is applied to the robots that which can speak and behave like human while just leaning on what they had learned and been taught beforehand. This is the most accurate definition because it is simply closer to what they are expected to do in general sense.
AI is not a robot that can handle certain tasks as it is programmed that way. So it would do no harm if we were eliminate Google Assistant or iOS Siri as candidates from the list of AIs because they simply do what they are able to do which is not more or not less.

Current Understanding

It would not be wrong saying that most people don’t have any expectation from AI other than that they would destroy humanity or leave us behind as being less flawed in existence. However, when it comes to the question why they would destroy us most people say that “because they are smarter than we are.” However, it is a pessimistic and blind approach to what it could bring as they are failing to see what mankind done to itself and the nature before the real arrival of the AI. So in this section, I would like to mention why AI-powered androids cannot or would not easily destroy humanity before leading themselves into some unexpected evolution in terms of their working flow.
AI could destroy humanity if they are not aware what “to destroy” means. You see when we talk about on an AI, we attribute it the ability to judge, learn, speak, think and negotiate, so this means that it can be and is one of us whether it is weaker or stronger. Then it would be a bit funny to expect it to kill us before it goes kill itself. What I am trying to get at is that if they are to destroy us,  possibly their intention is not to destroy us or they have a too good reason to let us not live or exist on this planet.
I think it would be a good example bringing Marvin from Hitchhiker’s Guide to the Galaxy, an existentialist robot who hates being in existence and curse its creators throughout the story. He knows simply everything and every word coming from his mouth (or speakers) is pessimistic. He is not helpful in any circumstance because he is too much occupied with his thoughts on existence.
The topic of Artificial Intelligence does also bring the expectation of being worthless in  possible future because it would take over anything normally a human-being would do and there are a few people discussing what people would do in the age of AI and without really having purpose of living (jobs, work etc.). Elon Musk on the topic, he says, though without really giving an answer to that, admitting that people will be in despair if it is done after the establishment of civilization along with the Artificial Intelligence utilizing the current order. It is a totally acceptable debate on one perspective.

**What is Really Happening?**

In the age of technology not expecting an arrival from what we call highly intellectual androids (or simply AI-powered devices) would be a mistake. Sophie of 21st century clearly has blown our minds in a way that we had started to wish rather not to have any than to be destroyed. The controversial robot has said enough to scare many with a huge success of being known at the large scale of Earth. She even has an citizenship of Saudi Arabia.
What we nowadays call as “hype”,  the popular robot also said “I will destroy humanity,”  in a humorous way. Of course, most believed and highly affected by that statement. Strangely, the one and only robot could be able say that. However, there are also a group who believes that Sophie’s intellect is in fact not real.
Sophie’s development must be a strange one. I have never seen a company having that powerful AI and still showing it off. Here is the problem; an AI is not a toy and it is certainly not a parrot. The term AI suggest super-intelligence and Sophie simply is a toy which is still under development. I think they should have never shown her in the first place or should at least underline the fact that she is unable to think apart from what we expect from an AI.
There are also self-driving cars on production for daily use. They are also known for  AI-paired system which enables them to drive by themselves. When we consider planes, auto-pilot has been there for long, but as being interfered by many blocks cars could not behave like they are flying over the sky. They should see what is in front of them. That’s why they are recently been usable since their development started 5 or so years ago. It is certainly not perfect still and they don’t learn in the way as we know it. They follow patterns and they are still not perfect. Recently Uber’s self driving taxi, which always has a co-human-pilot, has failed to stop before pedestrian and ended up killing her.
Machine-learning is the another area where AI is often referred. It is used while harvesting big data with getting the help of an AI (which is another preprocessor to the patterns). As an example to this we can take Google Translate, which has recently changed its architecture to what they call “machine learning”. Of course it cannot work without the help humans who provides direct translations, corrections and, then the AI performs an action to pick the suitable word to the given context. Again it is not perfect but works better than the old one.
What Should be Expected?

As a human-being whether religious or not finding the answer or at least finding better question should be the aim. However, acceptance of the weakness is also an important milestone for us to improve. AI, in this sense, will allow us to reduce miscalculations on the journey of space or while creating new device which could enable us to see further. This can be, for instance, a new microscope. The human error or the capacity is always a limit for us that which should be exceeded in order to reduce time in development or to make it possible. These are the most beneficial outcome of this new technology.
The current development has not come close enough to the point where we can call it dangerous. AI’s possibility of destroying us is completely unavailable information to us. We cannot decide that it is the new threat to our kind. Even if it did, it would not be any worse that what mankind could do to itself. Because an AI under the right circumstances could not be more than a computer program. Giving it control over our lives could only lead that possibility.

**Understanding AI and Why We Fail to Develop One?**

The true AI has not yet been accomplished. We are just seeing prototypes of those we want to see in the future. Sophie is fake for sure, but the real question is what way of development should be followed in order to have a truly working AI. So in order to discuss on the question, we need to describe some useful understanding of human nature;
  • Randomness
    Our randomness which is just not random but also predictable is our shepherd in daily life. The combination of many different inputs which are our ears, eyes, senses, chemical state of our body and our brains comparing them to the old knowledge (or inputs) make us the person who we are. I am not expert in this, but it does not change the fact that I am a human. What we know as good and bad is coded through this mechanism.
  • Survival Instincts
    We all have it and I believe this might be the reason which caused us to develop languages. When a person gets hungry or its (consider animals also) body senses that it could die, for the environment provides what is beforehand provided as threat, this is triggered. Feeling the pain also has a big impact on this.

Building an AI should not be any different than raising a baby because only thus it could have a true conscious. A program reading the inputs as does humans or animal can really be improvement. When we look at the nature we see that animals with different shapes act and behave accordingly. So it might be true that to give a certain understanding to the program of life to help it make its way into being a real consciousness. This would make the learning the real learning ability.
I don’t think we will be able to make a program that truly understands us without having such a way of understanding of existence. What I am trying to say is that an AI cannot be created but be taught. That is why all the programs are failing. They don’t actually understand what they are doing or why they are doing. This is the meaning of life to us “having the feeling that we are living” therefore we seek the things that make life easier only when “survival instincts” are triggered.
Randomness is the conditions that could be judged with our knowledge. For example, if I have never been in a desert then I might not know that I will not be able find water in every 200 meters like I normally do, so I might die of lack of water. So this proves two things; one is that I know my need for water and the other is, therefore, the desert is dangerous to me. But if we put Sophie into desert, she would wait until her battery dies. This also proves Sophie is not a real AI and she has not the chemical reaction of pain that her battery is dying therefore she must do something. When she is charging, it will not trigger her hormones level up so that she would not be happy of the process and would not know why she is charging herself in the first place if she is not programmed that way.
I think these are the essential parts of the development of an AI. We can simply call it “providing a reasoning mechanism”.
